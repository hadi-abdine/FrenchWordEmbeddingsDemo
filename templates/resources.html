{% extends "base.html" %}
{% block title %} resources {% endblock %}
{% block content %}


<div class="card mb-3 mx-auto" style="max-width: 80%; border-radius: 25px">
  <!-- <div class="card-header text-white bg-primary" style="border-top-right-radius: 25px; border-top-left-radius: 25px" >Vector Word Representation For The French Language</div> -->
  <div class="card-body">
    <h1 class="card-title text-green" style="color:Green;">French linguistic resources</h1>
    <!-- <h6 class="card-subtitle mb-2 text-muted">Card subtitle</h6> -->
    <p class="card-text"></p>
    <!-- <a href="#" class="card-link">Card link</a> -->
    <!-- <a href="#" class="card-link">Another link</a> -->
    <ul class="nav nav-tabs mb-3" id="pills-tab" role="tablist">
      <li class="nav-item">
        <a class="nav-link active" id="pills-embd-tab" data-toggle="pill" href="#pills-embd" role="tab"
          aria-controls="pills-embd" aria-selected="true">Word Embeddings</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" id="pills-resources-tab" data-toggle="pill" href="#pills-resources" role="tab"
          aria-controls="pills-resources" aria-selected="false">BARThez</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" id="pills-corp-tab" data-toggle="pill" href="#pills-corp" role="tab"
          aria-controls="pills-corp" aria-selected="false">N-grams</a>
      </li>
      <!-- <li class="nav-item">
        <a class="nav-link" id="pills-uni-tab" data-toggle="pill" href="#pills-uni" role="tab" aria-controls="pills-uni"
          aria-selected="false">Unigrams</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" id="pills-bi-tab" data-toggle="pill" href="#pills-bi" role="tab" aria-controls="pills-bi"
          aria-selected="false">Bigrams</a>
      </li>
      <li class="nav-item">
        <a class="nav-link" id="pills-tri-tab" data-toggle="pill" href="#pills-tri" role="tab" aria-controls="pills-tri"
          aria-selected="false">Trigrams</a>
      </li> -->
    </ul>

    <div class="tab-content" id="pills-tabContent">
      <div class="tab-pane fade show active" id="pills-embd" role="tabpanel" aria-labelledby="pills-embd-tab">


        <ul class="nav nav-tabs mb-3" id="pills-tab" role="tablist">
          <li class="nav-item">
            <a class="nav-link active" id="pills-d1-tab" data-toggle="pill" href="#pills-d1" role="tab"
              aria-controls="pills-d1" aria-selected="true">fr_w2v_web_w5</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" id="pills-d2-tab" data-toggle="pill" href="#pills-d2" role="tab"
              aria-controls="pills-d2" aria-selected="false">fr_w2v_web_w20</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" id="pills-f1-tab" data-toggle="pill" href="#pills-f1" role="tab"
              aria-controls="pills-f1" aria-selected="false">fr_w2v_fl_w5</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" id="pills-f2-tab" data-toggle="pill" href="#pills-f2" role="tab"
              aria-controls="pills-f2" aria-selected="false">fr_w2v_fl_w20</a>
          </li>
        </ul>
        <div class="tab-content" id="pills-tabContent">
          <div class="tab-pane fade show active" id="pills-d1" role="tabpanel" aria-labelledby="pills-d1-tab">
            <p align="justify">French word vectors trained using word2vec CBOW with window size of 5 and minimum word
              frequency of 60. These vectors are trained on the 33GB deduplicated French raw text collected from the web 
              and preprocessed in our group.<br>
            </p>
            <ul>
              <!-- <li>.vec file : download (add link)</li> -->
              <li>binary file: <a
                  href="https://www.googleapis.com/drive/v3/files/1hs5D1XZAAqg6CdUWGoqO44YL1zCQsI_c?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
                  download</a></li>
            </ul>
          </div>
          <div class="tab-pane fade" id="pills-d2" role="tabpanel" aria-labelledby="pills-d2-tab">
            <p align="justify">French word vectors trained using word2vec CBOW with window size of 20 and minimum word
              frequency of 5. These vectors are trained on the 33GB deduplicated French raw text collected from the web 
              and preprocessed in our group. You can test these vectors in this web application.<br>
            </p>
            <ul>
              <!-- <li>.vec file : download (add link)</li> -->
              <li>binary file: <a
                  href="https://www.googleapis.com/drive/v3/files/19oroYX5kOZzfHS29mEaki5EUf2_vbVuA?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
                  download</a></li>
            </ul>
          </div>
          <div class="tab-pane fade" id="pills-f1" role="tabpanel" aria-labelledby="pills-f1-tab">
            <p align="justify">French word vectors trained using word2vec CBOW with window size of 5 and minimum word
              frequency of 60. These vectors are trained on a 33GB shuffled portion of the French corpus used to train FlauBERT.<br>
            </p>
            <ul>
              <!-- <li>.vec file : download (add link)</li> -->
              <li>binary file: <a
                  href="https://www.googleapis.com/drive/v3/files/1rxBWqupPzAvngemGUJqpP6Swyn5_aoj9?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
                  download</a></li>
            </ul>
          </div>
          <div class="tab-pane fade" id="pills-f2" role="tabpanel" aria-labelledby="pills-f2-tab">
            <p align="justify">French word vectors trained using word2vec CBOW with window size of 20 and minimum word
              frequency of 5. These vectors are trained on a 33GB shuffled portion of the French corpus used to train FlauBERT.<br>
            </p>
            <ul>
              <!-- <li>.vec file : download (add link)</li> -->
              <li>binary file: <a
                  href="https://www.googleapis.com/drive/v3/files/1N_Q_I7jOEUiqJ6Jr9805Ms_KOIDMoA28?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
                  download</a></li>
            </ul>
          </div>

        </div>

      </div>
      <div class="tab-pane fade" id="pills-resources" role="tabpanel" aria-labelledby="pills-resources-tab"
        align="justify">
        BARThez is the first french sequence to sequence pretrained model. <br>
        BARThez is pretrained on 66GB of french raw text for roughly 60 hours on 128 Nvidia V100 GPUs using the CNRS
        Jean Zay supercomputer (<a href="http://www.idris.fr/annonces/annonce-jean-zay-eng.html">
          http://www.idris.fr/annonces/annonce-jean-zay-eng.html</a>).
        Our model is based on BART (<a href="https://arxiv.org/abs/1910.13461">https://arxiv.org/abs/1910.13461</a>).
        Unlike already existing
        BERT-based French language models such as CamemBERT and FlauBERT, BARThez is particularly well-suited for
        generative tasks, since not only its encoder but also its decoder is pretrained.
        In addition to BARThez that is pretrained from scratch, we continue the pretraining of a multilingual BART
        mBART25 (<a href="https://arxiv.org/abs/2001.08210">https://arxiv.org/abs/2001.08210</a>) which boosted its
        performance in both discriminative and generative tasks. We call the french adapted version mBARThez.
        Our models are competitive to CamemBERT and FlauBERT in discriminative tasks and outperform them in
        generative tasks such as abstractive summarization.<br>
        Paper: <a href="https://arxiv.org/abs/2010.12321">https://arxiv.org/abs/2010.12321</a><br>
        Github: <a href="https://github.com/moussaKam/BARThez">https://github.com/moussaKam/BARThez</a><br>
      </div>
      <div class="tab-pane fade" id="pills-corp" role="tabpanel" aria-labelledby="pills-corp-tab">
        <ul>
          <li>List of cleaned uni-grams: <a
              href="https://www.googleapis.com/drive/v3/files/1t87ZuLXZNaafEMXdamb8LCsVLSPlAwIU?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
              download</a></li>
          <li>List of cleaned bi-grams: <a
              href="https://www.googleapis.com/drive/v3/files/14Gr3wZtrae1cjkwn6Ix-dxr8Wtch7Uf4?alt=media&key=AIzaSyDjjrSzhCDYWoLav6VQDaUm32i9mjSYg4E">
              download</a></li>
          <li>List of cleaned tri-grams: <a href=""> download</a></li>
        </ul>

      </div>
      <!-- <div class="tab-pane fade" id="pills-uni" role="tabpanel" aria-labelledby="pills-uni-tab">...</div>
      <div class="tab-pane fade" id="pills-bi" role="tabpanel" aria-labelledby="pills-bi-tab">...</div>
      <div class="tab-pane fade" id="pills-tri" role="tabpanel" aria-labelledby="pills-tri-tab">...</div> -->

      If you use these language resources, please cite the following papers: 
      <div class="card text-white bg-dark" style="border-radius: 25px">
            <div class="card-body">
              @misc{eddine2020barthez,<br>
                title={BARThez: a Skilled Pretrained French Sequence-to-Sequence Model}, <br>
                author={Moussa Kamal Eddine and Antoine J. -P. Tixier and Michalis Vazirgiannis},<br>
                year={2020},<br>
                eprint={2010.12321},<br>
                archivePrefix={arXiv},<br>
                primaryClass={cs.CL}<br>
                }
                <br><br>
                
            </div>
        </div>
    </div>
  </div>
</div>



{% endblock %}